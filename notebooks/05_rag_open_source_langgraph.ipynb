{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro-open-source-rag",
      "metadata": {},
      "source": [
        "# Clase 8 (RAG) – Versión 100% Open Source\n",
        "\n",
        "Stack: Ollama (Qwen 2.5 7B Instruct) + FAISS + HuggingFace Embeddings.\n",
        "Fuente: `PDF/9587014499.PDF` dentro del repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "setup-rag",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG listo. PDF: /home/wilson/Documentos/my_course_agent/notebooks/PDF/9587014499.PDF\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from dotenv import load_dotenv; load_dotenv()\n",
        "\n",
        "from langchain_ollama import ChatOllama\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "# Import actualizado (evita deprecación)\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "REPO_ROOT = Path.cwd().parents[0] if (Path.cwd()/\"notebooks\").exists() else Path.cwd()\n",
        "PDF_PATH = REPO_ROOT / \"PDF\" / \"9587014499.PDF\"\n",
        "INDEX_DIR = REPO_ROOT / \".rag_index\" / \"faiss-e5-small\"\n",
        "\n",
        "MODEL = os.getenv(\"MODEL\", \"qwen2.5:7b-instruct\")\n",
        "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
        "EMB_MODEL = os.getenv(\"EMB_MODEL_NAME\", \"intfloat/multilingual-e5-small\")\n",
        "\n",
        "CHUNK_SIZE = int(os.getenv(\"CHUNK_SIZE\", \"900\"))\n",
        "CHUNK_OVERLAP = int(os.getenv(\"CHUNK_OVERLAP\", \"150\"))\n",
        "TOP_K = int(os.getenv(\"TOP_K\", \"4\"))\n",
        "\n",
        "# Fuerza embeddings en CPU para evitar conflicto con Ollama usando GPU\n",
        "EMB = HuggingFaceEmbeddings(\n",
        "    model_name=EMB_MODEL,\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n",
        "\n",
        "LLM = ChatOllama(model=MODEL, base_url=OLLAMA_BASE_URL, temperature=0.2)\n",
        "\n",
        "INDEX_DIR.mkdir(parents=True, exist_ok=True)\n",
        "if (INDEX_DIR/\"index.faiss\").exists() and (INDEX_DIR/\"index.pkl\").exists():\n",
        "    vs = FAISS.load_local(INDEX_DIR, EMB, allow_dangerous_deserialization=True)\n",
        "else:\n",
        "    loader = PyPDFLoader(str(PDF_PATH))\n",
        "    docs = loader.load()\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "    chunks = splitter.split_documents(docs)\n",
        "    vs = FAISS.from_documents(chunks, EMB)\n",
        "    vs.save_local(INDEX_DIR)\n",
        "\n",
        "retriever = vs.as_retriever(search_kwargs={\"k\": TOP_K})\n",
        "\n",
        "system = (\n",
        "    \"Eres un asistente que responde SOLO con el contexto del PDF. \"\n",
        "    \"Si no está en el PDF, dilo claramente. Responde en español.\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system),\n",
        "    (\"human\", \"Pregunta: {question}\\n\\nContexto:\\n{context}\\n\\nRespuesta concisa y precisa:\")\n",
        "])\n",
        "\n",
        "def format_docs(docs):\n",
        "    out = []\n",
        "    for i, d in enumerate(docs, 1):\n",
        "        pg = (d.metadata or {}).get(\"page\", \"?\")\n",
        "        out.append(f\"[{i}] (pág. {pg}) {d.page_content.strip()}\")\n",
        "    return \"\\n\\n\".join(out)\n",
        "\n",
        "chain = ({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} \n",
        "         | prompt | LLM | StrOutputParser())\n",
        "\n",
        "print(\"RAG listo. PDF:\", PDF_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ask-example",
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Se calculan probabilidades condicionales y conjuntas para eventos V e E, resultando en P(V I E) = 5/12, P(E I V) = 4/9 y P(V) = 4/3.\n",
            "- Se presentan respuestas a ejercicios de probabilidad y estadística, incluyendo cálculos de probabilidades condicionales, esperanzas matemáticas y variables aleatorias.\n",
            "- Se discuten fórmulas para la expectación condicional y varianza en funciones de varias variables, junto con ejemplos específicos.\n",
            "- Se proporciona una demostración matemática sobre el comportamiento límite de funciones de distribución acumulativa en un espacio bidimensional.\n"
          ]
        }
      ],
      "source": [
        "q = \"Resume en 5 viñetas los puntos principales del documento.\"\n",
        "resp = chain.invoke(q)\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "good-practices",
      "metadata": {},
      "source": [
        "## Buenas prácticas\n",
        "- Cambia `EMB_MODEL` si quieres otro embedding open-source (p. ej., `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`).\n",
        "- Sube/edita más PDFs y genera índices separados en `.rag_index/`.\n",
        "- Integra la herramienta `rag_search` en tu grafo para usar RAG bajo demanda."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

# üí¨ Clase 5: Gesti√≥n de **historial de mensajes** en LangGraph

> Curso: **Crear Agentes de AI con LangGraph**  
> Objetivo: Modelar una **memoria conversacional** fiable con LangGraph: tipos de mensajes de LangChain, estado con `messages`, patr√≥n de agregado sin sobrescribir y pruebas r√°pidas en consola/Studio.

---

## üß† Por qu√© importa el historial
Un buen agente necesita **contexto** para mantener conversaciones coherentes y √∫tiles. Sin historial, cada interacci√≥n ser√≠a aislada, como hablar con alguien con amnesia cada vez.

LangGraph integra el historial como parte del **estado compartido**, de modo que cada nodo ‚Äúve‚Äù la conversaci√≥n completa y decide en consecuencia. Por ejemplo, si el usuario dice "Recu√©rdame mi nombre" en el turno 3, el nodo puede acceder a mensajes previos para responder "Te llamas Nicol√°s, como dijiste al inicio".

- **Beneficios**: Evita repeticiones, permite referencias cruzadas y mejora la personalizaci√≥n.
- **Desaf√≠os**: Historiales largos consumen tokens (costos) y pueden confundir al LLM si no se gestionan.
- **Soluci√≥n en LangGraph**: Usa agregadores como `add_messages` para acumular mensajes autom√°ticamente, y estrategias como ventanas deslizantes para controlar el tama√±o.

---

## üßæ Tipos de mensajes (LangChain)
LangChain define tipos de mensajes para estructurar conversaciones de manera est√°ndar. Cada tipo tiene un rol espec√≠fico en el flujo.

| Tipo | Para qu√© sirve | Ejemplo de uso | Nota |
|---|---|---|---|
| `HumanMessage` | Mensaje de la persona usuaria | Entrada del usuario | Marca el rol de usuario; siempre inicia con esto en consultas |
| `AIMessage` | Respuesta del agente | Salida del LLM | El modelo responde con este tipo; se acumula en historial |
| `SystemMessage` | Instrucciones de sistema | Gu√≠a estilo, reglas o contexto | Invisible al usuario; establece comportamiento del agente |
| `ToolMessage` | I/O con herramientas externas | Registra llamadas a tools y resultados | Usado en agentes con herramientas; incluye tool name y output |
| `BaseMessage` | Clase base | Tipo gen√©rico para listas mixtas | √ötil para tipar `list[BaseMessage]` sin especificar |

### Ejemplos de creaci√≥n:
```python
from langchain_core.messages import (
    HumanMessage, AIMessage, SystemMessage, ToolMessage, BaseMessage
)

# Mensaje del usuario
user = HumanMessage(content="Hola, soy Nico.")

# Respuesta del agente
ai = AIMessage(content="¬°Hola Nico! ¬øEn qu√© te ayudo?")

# Instrucci√≥n del sistema
system = SystemMessage(content="Eres un asistente √∫til y siempre respondes en espa√±ol.")

# Resultado de una tool (ej. b√∫squeda)
tool = ToolMessage(content="El clima en Bogot√° es 22¬∞C.", tool_call_id="search_01")

# Lista mixta
messages: list[BaseMessage] = [system, user, ai, tool]
```

Estos tipos permiten al LLM entender el contexto y roles en la conversaci√≥n, mejorando la calidad de respuestas.

---

## üß© Dos formas v√°lidas de modelar el estado con historial

Elige la opci√≥n que mejor se adapte a tu agente: simple si solo necesitas historial, flexible si agregas m√°s datos.

### Opci√≥n A (r√°pida): usar `MessagesState`
Ideal cuando **solo** gestionas historial de mensajes (y quiz√°s 1-2 claves simples). Es predefinido y minimalista.

```python
from langgraph.graph import MessagesState, StateGraph, START, END
from langchain_core.messages import HumanMessage, AIMessage

def bot_node(state: MessagesState) -> dict:
    """
    Nodo simple: lee historial, encuentra √∫ltimo HumanMessage,
    responde basado en √©l.
    """
    history = state["messages"]
    last_user = next((m for m in reversed(history) if isinstance(m, HumanMessage)), None)
    text = last_user.content if last_user else "Hola üëã"
    # Devuelve SOLO lo nuevo; LangGraph lo agrega al final autom√°ticamente
    return {"messages": [AIMessage(content=f"Entendido: {text}")]}

# Construir grafo
builder = StateGraph(MessagesState)
builder.add_node("bot", bot_node)
builder.add_edge(START, "bot")
builder.add_edge("bot", END)
app = builder.compile()
```

- **Ventajas**: C√≥digo corto; `MessagesState` maneja agregaci√≥n por defecto.
- **Limitaciones**: Dif√≠cil agregar claves extras (necesitas `TypedDict` personalizado).
- **Uso t√≠pico**: Agentes b√°sicos de chat sin memoria adicional.

### Opci√≥n B (flexible): `TypedDict` + agregador `add_messages`
Cuando necesitas historial **m√°s otras claves** (memoria persistente, flags, contadores, etc.). M√°s extensible para agentes complejos.

```python
from typing import TypedDict, Sequence, Optional
from typing_extensions import Annotated
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage

class State(TypedDict, total=False):
    messages: Annotated[Sequence[BaseMessage], add_messages]  # Agrega, no pisa
    customer_name: Optional[str]  # Memoria de usuario
    turn_count: int              # Contador de turnos

def ensure_name(state: State) -> dict:
    """Nodo: Establece nombre si falta."""
    if not state.get("customer_name"):
        return {"customer_name": "John Doe"}
    return {}

def reply(state: State) -> dict:
    """Nodo: Responde usando historial y estado."""
    history = state.get("messages", [])
    last_user = next((m for m in reversed(history) if isinstance(m, HumanMessage)), None)
    text = last_user.content if last_user else "¬øSeguimos?"
    turn = state.get("turn_count", 0) + 1
    return {
        "messages": [AIMessage(content=f"Turno {turn}: recib√≠ ‚Äú{text}‚Äù.")],
        "turn_count": turn,
    }

# Construir grafo (agrega nodos y edges seg√∫n necesites)
# builder = StateGraph(State)
# ...
```

- **Ventajas**: Flexible para crecer; combina historial con l√≥gica de negocio.
- **Agregador `add_messages`**: Acumula mensajes sin sobrescribir; clave para mantener conversaci√≥n.
- **Uso t√≠pico**: Agentes con memoria, herramientas o m√∫ltiples ramas.

---

## üï∏Ô∏è Orquestaci√≥n con `StateGraph`

Conecta nodos en un flujo usando `StateGraph`. Aqu√≠ un ejemplo con la opci√≥n B (flexible).

```python
from langgraph.graph import StateGraph, START, END

# Usa tu State personalizado (o MessagesState para opci√≥n A)
builder = StateGraph(State)

# Agregar nodos (funciones definidas arriba)
builder.add_node("ensure_name", ensure_name)
builder.add_node("reply", reply)

# Definir flujo secuencial con edges
builder.add_edge(START, "ensure_name")  # Inicio ‚Üí ensure_name
builder.add_edge("ensure_name", "reply") # ensure_name ‚Üí reply
builder.add_edge("reply", END)            # reply ‚Üí Fin

# Compilar en app invocable
app = builder.compile()
```

- **Proceso**:
  1. `StateGraph(State)`: Crea builder con tu tipo de estado.
  2. `add_node`: Registra funciones como nodos ejecutables.
  3. `add_edge`: Conecta nodos en orden (secuencial aqu√≠).
  4. `compile()`: Genera `app` listo para `invoke()`.
- **Flujo resultante**: START ‚Üí ensure_name (establece nombre si falta) ‚Üí reply (responde usando historial) ‚Üí END.

> **Regla de oro:** Cada nodo **devuelve solo** las claves que modific√≥ (ej. `{"messages": [...], "turn_count": 1}`). LangGraph fusiona autom√°ticamente en el estado global, evitando conflictos.

---

## ‚ûï A√±adir mensajes sin errores (patr√≥n correcto)
El agregador `add_messages` simplifica la acumulaci√≥n de mensajes. Sigue estos patrones para evitar errores comunes.

- **Con `add_messages` (recomendado)**:
  - No concatenes listas manualmente.
  - Simplemente retorna `{"messages": [nuevo_msg]}`; LangGraph hace append autom√°ticamente.
  - Ejemplo: `return {"messages": [AIMessage(content="Hola")]}` agrega al historial existente.

- **Si gestionas listas t√∫ mismo** (menos com√∫n, fuera de `add_messages`):
  - Usa concatenaci√≥n correcta para listas:
    ```python
    history = state.get("history", []) + [AIMessage(content="nuevo")]  # ‚úÖ lista + lista
    # history = history + AIMessage(...)  # ‚ùå error: no concatenes objeto suelto
    ```
  - Raz√≥n: Python requiere tipos compatibles; `list + obj` falla.

- **Consejo**: Siempre usa `add_messages` en `State` para mensajes; es m√°s seguro y autom√°tico.

Este patr√≥n asegura que el historial crezca correctamente sin perder mensajes previos.

---

## üîé Depurar el historial r√°pidamente
Para entender qu√© pasa en el historial, imprime mensajes de forma clara y legible. Evita depender de m√©todos internos.

```python
def dump_messages(history):
    """
    Funci√≥n helper: imprime historial con n√∫mero, rol y contenido.
    √ösala en nodos para debugging: dump_messages(state.get("messages", []))
    """
    for i, m in enumerate(history, 1):
        # Extrae rol del tipo de mensaje (HumanMessage -> human)
        role = m.__class__.__name__.replace("Message", "").lower()
        print(f"{i:02d} [{role}] {m.content}")

# Ejemplo de uso en nodo
def debug_node(state: State) -> dict:
    print("Historial actual:")
    dump_messages(state.get("messages", []))
    return {}  # Sin cambios
```

- **Por qu√© √∫til**: Muestra el flujo real de mensajes (ej. "01 [human] Hola", "02 [ai] ¬°Hola!").
- **Consejo**: Agrega prints temporales en nodos para rastrear c√≥mo crece el historial.
- **Avanzado**: Usa en combinaci√≥n con `thread_id` en Studio para ver persistencia.

Esta funci√≥n te ayuda a detectar problemas como mensajes duplicados o perdidos.

---

## ‚ñ∂Ô∏è Pruebas r√°pidas (CLI) y en Studio

Prueba tu agente para verificar que el historial se acumule correctamente.

### En CLI (con helper function):
Agrega esto a tu `main.py` para pruebas r√°pidas:
```python
from langchain_core.messages import HumanMessage

def ask(text: str) -> str:
    """
    Helper: Toma texto, lo envuelve en HumanMessage,
    invoca el grafo y devuelve la √∫ltima respuesta.
    """
    result = app.invoke({"messages": [HumanMessage(content=text)]})
    return result["messages"][-1].content

# Prueba en terminal
# uv run python -c "from agents.main import ask; print(ask('Hola, soy Nico'))"
```

- **Ejemplo output**: "¬°Hola Nico! ¬øEn qu√© te ayudo?" (usa nombre si disponible).
- **Consejo**: Invoca m√∫ltiples veces para ver acumulaci√≥n: el segundo mensaje deber√≠a recordar el contexto.

### En LangGraph Studio (visual):
1. Ejecuta `uv run langgraph dev` (servidor en localhost:2024).
2. Abre el navegador y selecciona tu grafo (ej. "agent").
3. Crea un **thread** nuevo (para estado aislado).
4. Env√≠a un `HumanMessage` como "Hola, soy Nico".
5. Observa: Se agrega un `AIMessage` de respuesta **sin borrar** mensajes previos.
6. Env√≠a otro mensaje: El historial completo se usa para contexto.

Studio muestra el flujo en tiempo real, ideal para ver c√≥mo `add_messages` acumula mensajes.

---

## üß† Estrategias de contexto (tokens/costos)
Historiales largos consumen tokens (costos en APIs como OpenAI) y pueden confundir al LLM. Usa estas estrategias para optimizar.

- **Ventana deslizante**: Mant√©n solo los **k** √∫ltimos mensajes (ej. √∫ltimos 10). Implementa en un nodo: `recent = state["messages"][-10:]`.
- **Resumen peri√≥dico**: Cada N turnos, pide al LLM un resumen del historial y reemplaza mensajes antiguos. Ejemplo: nodo `summarize` que genera un `SystemMessage` con summary.
- **Contexto por nodo**: Cada nodo decide qu√© leer. Ej: nodo de herramientas usa solo √∫ltimos mensajes; nodo de memoria usa todo.
- **Tool traces**: Conserva `ToolMessage` para auditor√≠a (qu√© tools se llamaron y resultados), pero resume si es largo.
- **Otras**: Filtra por tipo (solo Human/AI, ignora System viejos) o usa embeddings para seleccionar mensajes relevantes.

Elige basado en costos vs precisi√≥n: m√°s contexto = mejor respuestas, pero m√°s tokens.

---

## üõü Problemas comunes y soluciones
Errores frecuentes con historial y c√≥mo resolverlos r√°pidamente.

- **`KeyError` al leer estado** (ej. "customer_name"):
  - Causa: Clave no existe en estado inicial.
  - Soluci√≥n: Usa `state.get("clave", "default")` en lugar de `state["clave"]`.

- **Historial se sobreescribe** (pierdes mensajes previos):
  - Causa: No usas agregador o reasignas `messages` directamente.
  - Soluci√≥n: Define `messages` con `add_messages` en `State`; devuelve `{"messages": [nuevo]}`.

- **No aparece respuesta** (nodo no agrega mensaje):
  - Causa: Nodo no retorna `{"messages": [AIMessage(...)]}`.
  - Soluci√≥n: Verifica que el nodo devuelva el dict correcto; prueba con prints.

- **Imports rotos** (ModuleNotFoundError al importar):
  - Causa: Carpetas sin `__init__.py` o instalaci√≥n editable rota.
  - Soluci√≥n: Agrega `__init__.py` en `src/agents/`; corre `uv pip install -e .` tras cambios.

Usa `dump_messages` (definida arriba) en nodos para inspeccionar el estado en tiempo real.

---

## ‚úÖ Checklist
Verifica que tu agente maneje historial correctamente antes de a√±adir complejidad.

- [ ] Estado definido con `messages` (usa `MessagesState` para simple o `TypedDict` + `add_messages` para flexible).
- [ ] Nodos implementados devolviendo solo cambios (ej. `{"messages": [AIMessage(...)]}` para append autom√°tico).
- [ ] Grafo compilado y probado en CLI (respuestas coherentes con contexto).
- [ ] Probado en LangGraph Studio (crea thread, env√≠a mensajes, verifica acumulaci√≥n sin sobrescritura).
- [ ] Estrategia b√°sica de contexto/tokens decidida (ej. ventana deslizante si necesitas optimizar costos).

Si todo est√° marcado, tu agente mantiene conversaciones coherentes.

**Siguiente clase ‚Üí** Branching y tools: c√≥mo hacer que el agente tome decisiones condicionales y ejecute acciones externas (como b√∫squedas o c√°lculos).

# Clase 10 â€” Respuestas Estructuradas en LLMs para Agentes

**Objetivo:** Aprender a controlar las respuestas de los LLMs usando salidas estructuradas (structured output) con Pydantic y LangChain, enfocÃ¡ndonos en herramientas open source como Ollama. Esto permite extraer datos confiables de conversaciones para usar en agentes con LangGraph, mejorando precisiÃ³n y control.

---

## ğŸ§  Â¿Por QuÃ© Estructurar Respuestas de LLMs?
Controlar cÃ³mo responde un modelo de lenguaje es esencial para agentes que toman decisiones seguras. Pasar de respuestas libres a estructuradas transforma texto impredecible en datos Ãºtiles, como nombres, emails o sentimientos, que puedes evaluar y usar en cÃ³digo.

- **Problema con respuestas libres:** Dependiendo del tono, longitud o temperatura, las respuestas varÃ­an mucho, lo que complica su uso en agentes.
- **SoluciÃ³n con structured output:** Fuerza al modelo a devolver un objeto JSON con un esquema claro (usando Pydantic), facilitando operaciones en el grafo del agente.
- **Beneficios:**
  - **EvaluaciÃ³n programÃ¡tica:** Extrae variables como nombre, email o tono para decisiones automÃ¡ticas.
  - **Decisiones en agentes:** Un nodo puede ramificar basado en datos consistentes.
  - **MÃ¡s que chat:** El modelo actÃºa como extractor confiable, no solo conversador.

Esto reduce impredecibilidad y costos al evitar respuestas ambiguas.

---

## ğŸ”‘ Conceptos BÃ¡sicos
Ideas clave para implementar structured output de forma efectiva.

- **Structured Output:** TÃ©cnica para que el LLM devuelva datos en un formato predefinido (ej. JSON con campos especÃ­ficos), usando esquemas como Pydantic.
- **Pydantic:** LibrerÃ­a Python para definir modelos de datos con validaciÃ³n automÃ¡tica. Traduce clases a esquemas JSON para el LLM.
- **IntegraciÃ³n con LangChain:** Usa `with_structured_output()` en modelos como ChatOllama para forzar respuestas estructuradas.
- **Ventajas sobre JSON mode antiguo:** MÃ¡s robusto y nativo en modelos modernos, sin depender de modos obsoletos.

---

## âœ… Requisitos
- Python â‰¥ 3.11
- uv instalado
- Ollama corriendo (para modelos locales open source)
- Dependencias: `uv add langchain langchain-ollama pydantic`

---

## âš™ï¸ ImplementaciÃ³n BÃ¡sica con Ollama
Crea un extractor que use structured output para extraer informaciÃ³n de una conversaciÃ³n.

### Definir el Esquema con Pydantic
```python
from pydantic import BaseModel, Field
from typing import Optional

class ContactInfo(BaseModel):
    name: Optional[str] = Field(description="Nombre de la persona, si se menciona explÃ­citamente.")
    email: Optional[str] = Field(description="Email, si se proporciona.")
    phone: Optional[str] = Field(description="TelÃ©fono, si se da.")
    tone: Optional[str] = Field(description="Tono de la conversaciÃ³n: positivo, negativo o neutral.")
    age: Optional[int] = Field(description="Edad, si se menciona como nÃºmero entero.")
```

- **ExplicaciÃ³n:** Cada campo tiene una descripciÃ³n clara para guiar al LLM. Usa `Optional` para campos que pueden no estar presentes.

### Configurar el LLM con Structured Output
```python
import os
from dotenv import load_dotenv
from langchain_ollama import ChatOllama

load_dotenv()
MODEL = os.getenv("MODEL", "qwen2.5:7b-instruct")
BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")

llm = ChatOllama(model=MODEL, base_url=BASE_URL)
llm_structured = llm.with_structured_output(ContactInfo)
```

- **Ventajas open source:** Usa Ollama para modelos locales, sin costos ni datos externos.

### Usar el Extractor en CÃ³digo
```python
from langchain_core.messages import HumanMessage, SystemMessage

# Mensajes de ejemplo
messages = [
    SystemMessage(content="Extrae informaciÃ³n de contacto de la conversaciÃ³n siguiente el esquema."),
    HumanMessage(content="Hola, me llamo Juan, tengo 25 aÃ±os y mi email es juan@example.com. Estoy emocionado por este curso.")
]

# Invocar el LLM estructurado
response = llm_structured.invoke(messages)
print(response)  # ContactInfo(name='Juan', email='juan@example.com', tone='positivo', age=25)
```

- **CÃ³mo funciona:** El LLM recibe el esquema y devuelve un objeto Pydantic validado. Puedes acceder a campos directamente: `response.name`.

---

## ğŸ› ï¸ IntegraciÃ³n en un Agente con LangGraph
Agrega un nodo extractor a tu grafo para extraer datos y usarlos en otros nodos.

### Estado con Datos ExtraÃ­dos
```python
from typing import TypedDict, Sequence
from typing_extensions import Annotated
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages

class State(TypedDict, total=False):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    contact_info: Optional[ContactInfo]  # Datos extraÃ­dos
```

### Nodo Extractor
```python
def extract_info(state: State) -> dict:
    """Nodo: Extrae informaciÃ³n estructurada del historial."""
    messages = list(state.get("messages", []))
    if not messages:
        return {}
    
    # Agregar system prompt para extracciÃ³n
    system_msg = SystemMessage(content="Extrae informaciÃ³n de contacto de la conversaciÃ³n. Si no encuentras un dato, no lo inventes.")
    full_messages = [system_msg] + messages
    
    # Invocar LLM estructurado
    response = llm_structured.invoke(full_messages)
    return {"contact_info": response}
```

### Nodo que Usa los Datos
```python
def respond_with_info(state: State) -> dict:
    """Nodo: Responde usando datos extraÃ­dos."""
    contact = state.get("contact_info")
    name = contact.name if contact else "usuario"
    
    user_msg = next((m for m in reversed(state.get("messages", [])) if isinstance(m, HumanMessage)), None)
    if user_msg:
        response = f"Hola {name}, gracias por tu mensaje: '{user_msg.content}'. Â¿En quÃ© mÃ¡s te ayudo?"
        return {"messages": [AIMessage(content=response)]}
    return {}
```

### Construir el Grafo
```python
from langgraph.graph import StateGraph, START, END

builder = StateGraph(State)
builder.add_node("extract", extract_info)
builder.add_node("respond", respond_with_info)

builder.add_edge(START, "extract")
builder.add_edge("extract", "respond")
builder.add_edge("respond", END)

app = builder.compile()
```

- **Flujo:** START â†’ extract (extrae datos) â†’ respond (usa datos en respuesta) â†’ END.
- **Beneficios:** Datos consistentes fluyen entre nodos, mejorando personalizaciÃ³n.

---

## ğŸ“ Buenas PrÃ¡cticas
Consejos para evitar errores comunes en structured output.

- **Evita alucinaciones:** En el system prompt, agrega "Si no encuentras el dato en la conversaciÃ³n, devuelve null o vacÃ­o. No inventes."
- **Maneja validaciones:** Usa tipos flexibles (Optional) para campos no obligatorios. Prueba con datos reales.
- **Optimiza costos:** Ejecuta el extractor solo cuando sea necesario (ej. si falta info o historial largo).
- **Pruebas:** Usa ejemplos variados para validar el esquema. Ajusta descripciones si el modelo falla.
- **Open source focus:** Siempre usa Ollama o modelos Hugging Face para mantener privacidad y cero costos.

---

## ğŸ§ª Ejercicios PrÃ¡cticos
Practica con estos ejercicios para reforzar conceptos.

1. **Esquema personalizado:** Crea un esquema para extraer "producto" y "precio" de mensajes de compra. Integra en un nodo de agente.
2. **Manejo de errores:** Modifica el extractor para manejar casos donde el LLM devuelve datos invÃ¡lidos (usa try/except con Pydantic).
3. **ExtracciÃ³n condicional:** Agrega lÃ³gica para extraer solo si el historial tiene >5 mensajes.

Estos ejercicios preparan para agentes mÃ¡s robustos.

---

## âœ… Checklist
- [ ] Esquema Pydantic definido con campos claros y descripciones.
- [ ] LLM configurado con `with_structured_output()`.
- [ ] Nodo extractor integrado en grafo LangGraph.
- [ ] Probado con mensajes reales (respuestas vÃ¡lidas y consistentes).
- [ ] Errores comunes mitigados (alucinaciones, validaciones).

Si todo estÃ¡ marcado, dominas structured output en agentes open source.

---

## ğŸ“š Recursos Open Source
- [LangChain Structured Output Docs](https://python.langchain.com/docs/how_to/structured_output/)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Ollama para Modelos Locales](https://ollama.ai/)

---

## ğŸ¤” Preguntas para Reflexionar
- Â¿CÃ³mo mejorarÃ­as el esquema para evitar alucinaciones en tus agentes?
- Â¿DÃ³nde aplicarÃ­as structured output en proyectos reales?
- Â¿QuÃ© otros datos estructurados extraerÃ­as de conversaciones?

**Siguiente clase â†’** MÃ¡s patrones avanzados de agentes con herramientas y memoria.

